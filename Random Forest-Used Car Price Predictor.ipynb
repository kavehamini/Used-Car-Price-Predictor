{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest-Used Car Price Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine,inspect, func\n",
    "from config import password\n",
    "\n",
    "import seaborn as sns\n",
    "import scipy.stats as ss\n",
    "from collections import Counter\n",
    "import math \n",
    "from scipy import stats\n",
    "import datetime\n",
    "import matplotlib\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from spark_sklearn import GridSearchCV\n",
    "from spark_sklearn.util import createLocalSparkSession\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.compat import lzip\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the sql database\n",
    "connection_string = \"postgres:\"+password+\"@localhost:5432/hondadb\"\n",
    "engine = create_engine(f'postgresql://{connection_string}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = pd.read_sql(\"SELECT * FROM cleanedcardb2\",\n",
    "                     con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned[['Price', 'Milage', 'Year', 'Model', 'Car Type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Milage</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>23678.000000</td>\n",
       "      <td>23678.000000</td>\n",
       "      <td>23678.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.125652</td>\n",
       "      <td>83962.430400</td>\n",
       "      <td>2016.588563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.600543</td>\n",
       "      <td>63802.640491</td>\n",
       "      <td>3.074993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.309881</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1995.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.728315</td>\n",
       "      <td>37345.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.165275</td>\n",
       "      <td>69000.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.570977</td>\n",
       "      <td>116000.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12.042377</td>\n",
       "      <td>500000.000000</td>\n",
       "      <td>2021.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Price         Milage          Year\n",
       "count  23678.000000   23678.000000  23678.000000\n",
       "mean      10.125652   83962.430400   2016.588563\n",
       "std        0.600543   63802.640491      3.074993\n",
       "min        7.309881      10.000000   1995.000000\n",
       "25%        9.728315   37345.000000   2015.000000\n",
       "50%       10.165275   69000.000000   2017.000000\n",
       "75%       10.570977  116000.000000   2019.000000\n",
       "max       12.042377  500000.000000   2021.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Car Type', 'Model']\n",
    "les = {}\n",
    "\n",
    "for f in features:\n",
    "  les[f] = preprocessing.LabelEncoder()\n",
    "  les[f] = les[f].fit(df_cleaned[f])\n",
    "  df_cleaned[f] = les[f].transform(df_cleaned[f])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test sets\n",
    "train_set, test_set = train_test_split(df_cleaned, test_size = 0.3, random_state = 100)\n",
    "\n",
    "# Separating target labels from the rest\n",
    "df_train = train_set.drop(\"Price\", axis=1) #train without target\n",
    "df_price_train = train_set[\"Price\"].copy() #target\n",
    "\n",
    "df_test  = test_set.drop(\"Price\", axis=1)\n",
    "df_price_test = test_set[\"Price\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Score Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns the best score achieved by the model over all the cv splits\n",
    "def best_score(forest, cv):\n",
    "  best_score = 0\n",
    "  for i in range(0, cv):\n",
    "    items = list(map(lambda x: abs(x), forest.cv_results_['split'+str(i)+'_test_score']))\n",
    "    arr = np.append(best_score, items)\n",
    "    best_score = max(arr)\n",
    "  \n",
    "  return best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Param Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This functions returns the best combination of parameters, which allows to\n",
    "# get the best score\n",
    "def best_params(forest):\n",
    "  return forest.cv_results_['params'][forest.cv_results_['rank_test_score'][0]-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Metric Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def performance_metric(y_true, y_predict):\n",
    "    \"\"\" Calculates and returns the performance score between \n",
    "        true (y_true) and predicted (y_predict) values based on the metric chosen. \"\"\"\n",
    "    \n",
    "    score = r2_score(y_true, y_predict)\n",
    "    \n",
    "    # Return the score\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaveh\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# Import 'make_scorer', 'DecisionTreeRegressor', and 'GridSearchCV'\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def RF_SparkizedGridSearchCV(X, y):\n",
    "    \"\"\" Performs grid search over the 'max_depth' parameter for a \n",
    "        decision tree regressor trained on the input data [X, y]. \"\"\"\n",
    "    \n",
    "    # Create cross-validation sets from the training data\n",
    "    cv_sets = ShuffleSplit(n_splits = 10, test_size = 0.20, random_state = 100)\n",
    "\n",
    "    # Create a decision tree regressor object\n",
    "    regressor = RandomForestRegressor()\n",
    "\n",
    "    # Create a dictionary for the parameter 'max_depth' with a range from 1 to 10\n",
    "    params = {'max_depth':[16, 17, 18]}\n",
    "\n",
    "    # Transform 'performance_metric' into a scoring function using 'make_scorer' \n",
    "    scoring_fnc = make_scorer(performance_metric)\n",
    "\n",
    "    # Create the grid search cv object --> GridSearchCV()\n",
    "    sc = createLocalSparkSession().sparkContext\n",
    "    grid = GridSearchCV(sc, estimator=regressor, param_grid=params, scoring=scoring_fnc, cv=cv_sets)\n",
    "\n",
    "    # Fit the grid search object to the data to compute the optimal model\n",
    "    tree_reg = grid.fit(X, y)\n",
    "    \n",
    "    # Return the best parameters after fitting the data\n",
    "    return tree_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter 'max_depth' is 18 for the optimal model.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# Fit the training data to the model using spark parallelized grid search CV\n",
    "forest_reg = RF_SparkizedGridSearchCV(df_train, df_price_train)\n",
    "\n",
    "# Takign best parameters\n",
    "bp = best_params(forest_reg)\n",
    "\n",
    "# Produce the optimal value for 'max_depth'\n",
    "print(\"Parameter 'max_depth' is {} for the optimal model.\".format(bp['max_depth']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 437 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=18,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the forest\n",
    "\n",
    "forest_reg_model = RandomForestRegressor(\n",
    "                              max_depth=bp['max_depth']\n",
    "                                 \n",
    ")\n",
    "\n",
    "%time forest_reg_model.fit(df_train, df_price_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 18}\n",
      "\n",
      "Random Forest Regressor score without CV on train set: 0.970\n",
      "Random Forest Regressor score without CV on test set: 0.875\n",
      "Random Forest Regressor Best score with CV=4: 0.879\n"
     ]
    }
   ],
   "source": [
    "# RandomForestRegressor score for price prediction\n",
    "\n",
    "print(bp)\n",
    "print(\"\\nRandom Forest Regressor score without CV on train set: %.3f\" % forest_reg_model.score(df_train, df_price_train)) #score on train set\n",
    "print(\"Random Forest Regressor score without CV on test set: %.3f\" % forest_reg_model.score(df_test, df_price_test)) #score on test set\n",
    "print(\"Random Forest Regressor Best score with CV=4: %.3f\" % best_score(forest_reg, 4)) # -> best score on test set is high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3993.895715057453"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction on whole training set\n",
    "price_predictions_train = forest_reg_model.predict(df_train) #using the whole training set for making prediction with the final model given by the best CV parameters\n",
    "\n",
    "# Reversing np.log operation\n",
    "price_predictions_train_normal = np.exp(price_predictions_train)\n",
    "df_price_train_normal = np.exp(df_price_train)\n",
    "\n",
    "# MSE between target values (i.e known) and predicted values\n",
    "lin_mse = mean_squared_error(df_price_train_normal, price_predictions_train_normal)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5919.86576954 50138.47248765 21746.48346395 13688.76778443\n",
      " 55093.59984985 34423.28024938  7435.61469308 36935.01166107\n",
      " 13454.88894071 23990.39604162]\n",
      "\n",
      "\n",
      "[5899.999999999999, 49486.999999998035, 21990.000000000084, 14995.000000000002, 76998.99999999984, 34498.000000000866, 6999.999999999999, 40278.99999999843, 13994.999999999933, 20883.999999999953]\n"
     ]
    }
   ],
   "source": [
    "print(price_predictions_train_normal[10:20])\n",
    "print('\\n')\n",
    "print(list(df_price_train_normal[10:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6685.352257930515"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "price_predictions_test = forest_reg_model.predict(df_test)\n",
    "\n",
    "# Reversing np.log operation\n",
    "price_predictions_test_normal = np.exp(price_predictions_test)\n",
    "df_price_test_normal = np.exp(df_price_test)\n",
    "\n",
    "final_mse = mean_squared_error(df_price_test_normal, price_predictions_test_normal)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "\n",
    "final_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13199.86120738 14375.22475689 14234.46850096 16070.70981831\n",
      " 24756.91364163 32996.67045384 27061.19287004 21565.22020348\n",
      " 39895.01200862 16471.83709271]\n",
      "\n",
      "\n",
      "[17994.999999999993, 11499.999999999976, 11994.99999999993, 23500.00000000118, 26887.9999999989, 28999.9999999997, 29189.000000000244, 21488.00000000001, 38952.99999999941, 13994.999999999933]\n"
     ]
    }
   ],
   "source": [
    "print(price_predictions_test_normal[10:20]) #predictions on test set\n",
    "print('\\n')\n",
    "print(list(df_price_test_normal[10:20])) #known values in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8476138600755545"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# r2 score between hold out prices and predicted prices\n",
    "r2_score(df_price_test_normal, price_predictions_test_normal, multioutput='variance_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model for type prediction\n",
    "pickle.dump(forest_reg_model, open(\"forest_reg_model_final.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model for type prediction\n",
    "forest_reg_model = pickle.load(open(\"forest_reg_model_final.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [7321.1910044  6400.12488291 6814.59379631 7249.9377581  6296.58911481\n",
      " 6960.40840939 7597.554986   7444.68600333 6193.49684415 6847.47943173]\n",
      "Mean: 6912.606223112741\n",
      "Standard deviation: 469.9322581786135\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Cross val score on training set, although we already used grid search CV\n",
    "train_scores = cross_val_score(forest_reg_model, df_train, np.exp(df_price_train),\n",
    "                         scoring=\"neg_mean_squared_error\", cv=KFold(10, shuffle=True))\n",
    "forest_rmse_scores = np.sqrt(-train_scores)\n",
    "\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.8037297  0.80599245 0.82237228]\n",
      "Mean: 0.8106981419818449\n",
      "Standard deviation: 0.008306385970368505\n"
     ]
    }
   ],
   "source": [
    "train_scores = cross_val_score(forest_reg_model, df_train, np.exp(df_price_train),\n",
    "                          cv=3)\n",
    "\n",
    "display_scores(train_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions on this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = forest_reg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on the hold out test set\n",
    "final_predictions = final_model.predict(df_test)\n",
    "\n",
    "final_mse = mean_squared_error(np.exp(df_price_test), np.exp(final_predictions))\n",
    "\n",
    "final_rmse = np.sqrt(final_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 6685.352258 \n",
      "Score on held-out Test Set: 0.875275 \n",
      "R2 Score: 0.847614\n"
     ]
    }
   ],
   "source": [
    "print(\"Test RMSE: %f \" % final_rmse)\n",
    "print(\"Score on held-out Test Set: %f \" % final_model.score(df_test, df_price_test))\n",
    "print(\"R2 Score: %f\" % r2_score(np.exp(df_price_test), np.exp(final_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [6212.33741784 5722.97694534 6262.58976859 5967.60706664 7595.54111088\n",
      " 6644.65166539 6377.69507141 6034.16188404 6711.14783089 6999.71133168]\n",
      "Mean: 6452.842009269651\n",
      "Standard deviation: 524.5450007854373\n"
     ]
    }
   ],
   "source": [
    "# Cross validation on the entire dataset, since we are good with out final model\n",
    "\n",
    "features = df_cleaned.drop(['Price'], axis=1)\n",
    "prices = df_cleaned['Price'].copy()\n",
    "\n",
    "final_rmses= cross_val_score(final_model, features, np.exp(prices),\n",
    "                          scoring=\"neg_mean_squared_error\", cv=KFold(10, shuffle=True))\n",
    "\n",
    "final_rmse_scores = np.sqrt(-final_rmses)\n",
    "display_scores(final_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.88426254 0.88650585 0.85957527 0.8750024  0.87546395 0.82625944\n",
      " 0.85570544 0.84598935 0.87191092 0.8521658 ]\n",
      "Mean: 0.8632840965520614\n",
      "Standard deviation: 0.017900211198537793\n"
     ]
    }
   ],
   "source": [
    "final_scores = cross_val_score(forest_reg_model, features, np.exp(prices),\n",
    "                          cv=KFold(10, shuffle=True))\n",
    "\n",
    "display_scores(final_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
