{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest-Used Car Price Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine,inspect, func\n",
    "from config import password\n",
    "\n",
    "import seaborn as sns\n",
    "import scipy.stats as ss\n",
    "from collections import Counter\n",
    "import math \n",
    "from scipy import stats\n",
    "import datetime\n",
    "import matplotlib\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from spark_sklearn import GridSearchCV\n",
    "from spark_sklearn.util import createLocalSparkSession\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.compat import lzip\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the sql database\n",
    "connection_string = \"postgres:\"+password+\"@localhost:5432/hondadb\"\n",
    "engine = create_engine(f'postgresql://{connection_string}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = pd.read_sql(\"SELECT * FROM cleanedcardb2\",\n",
    "                     con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned[['Price', 'Milage', 'Year', 'Model', 'Car Type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Milage</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1324.000000</td>\n",
       "      <td>1324.000000</td>\n",
       "      <td>1324.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.659139</td>\n",
       "      <td>85167.126888</td>\n",
       "      <td>2017.731873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.900439</td>\n",
       "      <td>59016.378417</td>\n",
       "      <td>2.525428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.837536</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>2011.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.790767</td>\n",
       "      <td>39400.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.819778</td>\n",
       "      <td>85000.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.460579</td>\n",
       "      <td>120689.000000</td>\n",
       "      <td>2020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12.021007</td>\n",
       "      <td>265000.000000</td>\n",
       "      <td>2020.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Price         Milage         Year\n",
       "count  1324.000000    1324.000000  1324.000000\n",
       "mean     10.659139   85167.126888  2017.731873\n",
       "std       0.900439   59016.378417     2.525428\n",
       "min       8.837536      90.000000  2011.000000\n",
       "25%       9.790767   39400.000000  2016.000000\n",
       "50%      10.819778   85000.000000  2019.000000\n",
       "75%      11.460579  120689.000000  2020.000000\n",
       "max      12.021007  265000.000000  2020.000000"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Car Type', 'Model']\n",
    "les = {}\n",
    "\n",
    "for f in features:\n",
    "  les[f] = preprocessing.LabelEncoder()\n",
    "  les[f] = les[f].fit(df_cleaned[f])\n",
    "  df_cleaned[f] = les[f].transform(df_cleaned[f])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test sets\n",
    "train_set, test_set = train_test_split(df_cleaned, test_size = 0.3, random_state = 100)\n",
    "\n",
    "# Separating target labels from the rest\n",
    "df_train = train_set.drop(\"Price\", axis=1) #train without target\n",
    "df_price_train = train_set[\"Price\"].copy() #target\n",
    "\n",
    "df_test  = test_set.drop(\"Price\", axis=1)\n",
    "df_price_test = test_set[\"Price\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Score Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns the best score achieved by the model over all the cv splits\n",
    "def best_score(forest, cv):\n",
    "  best_score = 0\n",
    "  for i in range(0, cv):\n",
    "    items = list(map(lambda x: abs(x), forest.cv_results_['split'+str(i)+'_test_score']))\n",
    "    arr = np.append(best_score, items)\n",
    "    best_score = max(arr)\n",
    "  \n",
    "  return best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Param Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This functions returns the best combination of parameters, which allows to\n",
    "# get the best score\n",
    "def best_params(forest):\n",
    "  return forest.cv_results_['params'][forest.cv_results_['rank_test_score'][0]-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Metric Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def performance_metric(y_true, y_predict):\n",
    "    \"\"\" Calculates and returns the performance score between \n",
    "        true (y_true) and predicted (y_predict) values based on the metric chosen. \"\"\"\n",
    "    \n",
    "    score = r2_score(y_true, y_predict)\n",
    "    \n",
    "    # Return the score\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 'make_scorer', 'DecisionTreeRegressor', and 'GridSearchCV'\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def RF_SparkizedGridSearchCV(X, y):\n",
    "    \"\"\" Performs grid search over the 'max_depth' parameter for a \n",
    "        decision tree regressor trained on the input data [X, y]. \"\"\"\n",
    "    \n",
    "    # Create cross-validation sets from the training data\n",
    "    cv_sets = ShuffleSplit(n_splits = 10, test_size = 0.20, random_state = 100)\n",
    "\n",
    "    # Create a decision tree regressor object\n",
    "    regressor = RandomForestRegressor()\n",
    "\n",
    "    # Create a dictionary for the parameter 'max_depth' with a range from 1 to 10\n",
    "    params = {'max_depth':[16, 17, 18]}\n",
    "\n",
    "    # Transform 'performance_metric' into a scoring function using 'make_scorer' \n",
    "    scoring_fnc = make_scorer(performance_metric)\n",
    "\n",
    "    # Create the grid search cv object --> GridSearchCV()\n",
    "    sc = createLocalSparkSession().sparkContext\n",
    "    grid = GridSearchCV(sc, estimator=regressor, param_grid=params, scoring=scoring_fnc, cv=cv_sets)\n",
    "\n",
    "    # Fit the grid search object to the data to compute the optimal model\n",
    "    tree_reg = grid.fit(X, y)\n",
    "    \n",
    "    # Return the best parameters after fitting the data\n",
    "    return tree_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter 'max_depth' is 16 for the optimal model.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# Fit the training data to the model using spark parallelized grid search CV\n",
    "forest_reg = RF_SparkizedGridSearchCV(df_train, df_price_train)\n",
    "\n",
    "# Takign best parameters\n",
    "bp = best_params(forest_reg)\n",
    "\n",
    "# Produce the optimal value for 'max_depth'\n",
    "print(\"Parameter 'max_depth' is {} for the optimal model.\".format(bp['max_depth']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 34 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=16,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the forest\n",
    "\n",
    "forest_reg_model = RandomForestRegressor(\n",
    "                              max_depth=bp['max_depth']\n",
    "                                 \n",
    ")\n",
    "\n",
    "%time forest_reg_model.fit(df_train, df_price_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 16}\n",
      "\n",
      "Random Forest Regressor score without CV on train set: 0.998\n",
      "Random Forest Regressor score without CV on test set: 0.991\n",
      "Random Forest Regressor Best score with CV=4: 0.994\n"
     ]
    }
   ],
   "source": [
    "# RandomForestRegressor score for price prediction\n",
    "\n",
    "print(bp)\n",
    "print(\"\\nRandom Forest Regressor score without CV on train set: %.3f\" % forest_reg_model.score(df_train, df_price_train)) #score on train set\n",
    "print(\"Random Forest Regressor score without CV on test set: %.3f\" % forest_reg_model.score(df_test, df_price_test)) #score on test set\n",
    "print(\"Random Forest Regressor Best score with CV=4: %.3f\" % best_score(forest_reg, 4)) # -> best score on test set is high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2394.066330868384"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction on whole training set\n",
    "price_predictions_train = forest_reg_model.predict(df_train) #using the whole training set for making prediction with the final model given by the best CV parameters\n",
    "\n",
    "# Reversing np.log operation\n",
    "price_predictions_train_normal = np.exp(price_predictions_train)\n",
    "df_price_train_normal = np.exp(df_price_train)\n",
    "\n",
    "# MSE between target values (i.e known) and predicted values\n",
    "lin_mse = mean_squared_error(df_price_train_normal, price_predictions_train_normal)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 94900.          85740.          10500.          42984.\n",
      "  94900.          85740.         143943.09828489  10988.\n",
      " 110000.         107652.46867957]\n",
      "\n",
      "\n",
      "[94899.99999999812, 85740.00000000272, 10499.999999999955, 42984.00000000184, 94899.99999999812, 85740.00000000272, 146995.00000000652, 10987.999999999942, 110000.0000000052, 100615.00000000323]\n"
     ]
    }
   ],
   "source": [
    "print(price_predictions_train_normal[10:20])\n",
    "print('\\n')\n",
    "print(list(df_price_train_normal[10:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5095.25710006018"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "price_predictions_test = forest_reg_model.predict(df_test)\n",
    "\n",
    "# Reversing np.log operation\n",
    "price_predictions_test_normal = np.exp(price_predictions_test)\n",
    "df_price_test_normal = np.exp(df_price_test)\n",
    "\n",
    "final_mse = mean_squared_error(df_price_test_normal, price_predictions_test_normal)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "\n",
    "final_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 17868.          85740.          57563.         105109.93060521\n",
      "  22990.         108094.46687347  49926.45203077  37999.\n",
      "  41158.          46314.09762755]\n",
      "\n",
      "\n",
      "[17868.0, 85740.00000000272, 57563.000000001215, 113774.99999999517, 22989.999999999374, 100615.00000000323, 66702.99999999985, 37999.00000000067, 66702.99999999985, 51720.99999999993]\n"
     ]
    }
   ],
   "source": [
    "print(price_predictions_test_normal[10:20]) #predictions on test set\n",
    "print('\\n')\n",
    "print(list(df_price_test_normal[10:20])) #known values in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9876317601259191"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# r2 score between hold out prices and predicted prices\n",
    "r2_score(df_price_test_normal, price_predictions_test_normal, multioutput='variance_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model for type prediction\n",
    "pickle.dump(forest_reg_model, open(\"forest_reg_model_final.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model for type prediction\n",
    "forest_reg_model = pickle.load(open(\"forest_reg_model_final.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [5404.53108243 4232.7109551  5594.59711766 5108.41831935 5620.91217764\n",
      " 5146.40928427 3414.18429    4442.85557482 5285.07558311 3920.32250003]\n",
      "Mean: 4817.001688440033\n",
      "Standard deviation: 725.3933345786228\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Cross val score on training set, although we already used grid search CV\n",
    "train_scores = cross_val_score(forest_reg_model, df_train, np.exp(df_price_train),\n",
    "                         scoring=\"neg_mean_squared_error\", cv=KFold(10, shuffle=True))\n",
    "forest_rmse_scores = np.sqrt(-train_scores)\n",
    "\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.99205952 0.99218875 0.98621446 0.98829996]\n",
      "Mean: 0.9896906710293627\n",
      "Standard deviation: 0.0025431290191954585\n"
     ]
    }
   ],
   "source": [
    "train_scores = cross_val_score(forest_reg_model, df_train, np.exp(df_price_train),\n",
    "                          cv=4)\n",
    "\n",
    "display_scores(train_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions on this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = forest_reg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on the hold out test set\n",
    "final_predictions = final_model.predict(df_test)\n",
    "\n",
    "final_mse = mean_squared_error(np.exp(df_price_test), np.exp(final_predictions))\n",
    "\n",
    "final_rmse = np.sqrt(final_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 5095.257100 \n",
      "Score on held-out Test Set: 0.990676 \n",
      "R2 Score: 0.987632\n"
     ]
    }
   ],
   "source": [
    "print(\"Test RMSE: %f \" % final_rmse)\n",
    "print(\"Score on held-out Test Set: %f \" % final_model.score(df_test, df_price_test))\n",
    "print(\"R2 Score: %f\" % r2_score(np.exp(df_price_test), np.exp(final_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [5461.89009207 3940.52957571 4983.5284795  4326.78472708 5846.92154438\n",
      " 4582.70371696 4914.61870832 6184.56937835 4784.92486863 3441.64350825]\n",
      "Mean: 4846.811459924036\n",
      "Standard deviation: 795.6935338710726\n"
     ]
    }
   ],
   "source": [
    "# Cross validation on the entire dataset, since we are good with out final model\n",
    "\n",
    "features = df_cleaned.drop(['Price'], axis=1)\n",
    "prices = df_cleaned['Price'].copy()\n",
    "\n",
    "final_rmses= cross_val_score(final_model, features, np.exp(prices),\n",
    "                          scoring=\"neg_mean_squared_error\", cv=KFold(10, shuffle=True))\n",
    "\n",
    "final_rmse_scores = np.sqrt(-final_rmses)\n",
    "display_scores(final_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.98892818 0.98651726 0.99101885 0.98478435 0.98284822 0.98428597\n",
      " 0.99313151 0.99272787 0.983935   0.99459796]\n",
      "Mean: 0.9882775177028966\n",
      "Standard deviation: 0.004133050242392499\n"
     ]
    }
   ],
   "source": [
    "final_scores = cross_val_score(forest_reg_model, features, np.exp(prices),\n",
    "                          cv=KFold(10, shuffle=True))\n",
    "\n",
    "display_scores(final_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
