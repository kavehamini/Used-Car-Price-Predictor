{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest-Used Car Price Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine,inspect, func\n",
    "from config import password\n",
    "\n",
    "import seaborn as sns\n",
    "import scipy.stats as ss\n",
    "from collections import Counter\n",
    "import math \n",
    "from scipy import stats\n",
    "import datetime\n",
    "import matplotlib\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from spark_sklearn import GridSearchCV\n",
    "from spark_sklearn.util import createLocalSparkSession\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.compat import lzip\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the sql database\n",
    "connection_string = \"postgres:\"+password+\"@localhost:5432/hondadb\"\n",
    "engine = create_engine(f'postgresql://{connection_string}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = pd.read_sql(\"SELECT * FROM cleanedcardb2\",\n",
    "                     con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned[['Price', 'Milage', 'Year', 'Model', 'Car Type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Milage</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>23677.000000</td>\n",
       "      <td>23677.000000</td>\n",
       "      <td>23677.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.125652</td>\n",
       "      <td>83959.113359</td>\n",
       "      <td>2016.588588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.600556</td>\n",
       "      <td>63801.946178</td>\n",
       "      <td>3.075055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.309881</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1995.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.728300</td>\n",
       "      <td>37344.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.165275</td>\n",
       "      <td>69000.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.570984</td>\n",
       "      <td>116000.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12.042377</td>\n",
       "      <td>500000.000000</td>\n",
       "      <td>2021.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Price         Milage          Year\n",
       "count  23677.000000   23677.000000  23677.000000\n",
       "mean      10.125652   83959.113359   2016.588588\n",
       "std        0.600556   63801.946178      3.075055\n",
       "min        7.309881      10.000000   1995.000000\n",
       "25%        9.728300   37344.000000   2015.000000\n",
       "50%       10.165275   69000.000000   2017.000000\n",
       "75%       10.570984  116000.000000   2019.000000\n",
       "max       12.042377  500000.000000   2021.000000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Car Type', 'Model']\n",
    "les = {}\n",
    "\n",
    "for f in features:\n",
    "  les[f] = preprocessing.LabelEncoder()\n",
    "  les[f] = les[f].fit(df_cleaned[f])\n",
    "  df_cleaned[f] = les[f].transform(df_cleaned[f])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test sets\n",
    "train_set, test_set = train_test_split(df_cleaned, test_size = 0.3, random_state = 100)\n",
    "\n",
    "# Separating target labels from the rest\n",
    "df_train = train_set.drop(\"Price\", axis=1) #train without target\n",
    "df_price_train = train_set[\"Price\"].copy() #target\n",
    "\n",
    "df_test  = test_set.drop(\"Price\", axis=1)\n",
    "df_price_test = test_set[\"Price\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Score Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns the best score achieved by the model over all the cv splits\n",
    "def best_score(forest, cv):\n",
    "  best_score = 0\n",
    "  for i in range(0, cv):\n",
    "    items = list(map(lambda x: abs(x), forest.cv_results_['split'+str(i)+'_test_score']))\n",
    "    arr = np.append(best_score, items)\n",
    "    best_score = max(arr)\n",
    "  \n",
    "  return best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Param Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This functions returns the best combination of parameters, which allows to\n",
    "# get the best score\n",
    "def best_params(forest):\n",
    "  return forest.cv_results_['params'][forest.cv_results_['rank_test_score'][0]-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Metric Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def performance_metric(y_true, y_predict):\n",
    "    \"\"\" Calculates and returns the performance score between \n",
    "        true (y_true) and predicted (y_predict) values based on the metric chosen. \"\"\"\n",
    "    \n",
    "    score = r2_score(y_true, y_predict)\n",
    "    \n",
    "    # Return the score\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 'make_scorer', 'DecisionTreeRegressor', and 'GridSearchCV'\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def RF_SparkizedGridSearchCV(X, y):\n",
    "    \"\"\" Performs grid search over the 'max_depth' parameter for a \n",
    "        decision tree regressor trained on the input data [X, y]. \"\"\"\n",
    "    \n",
    "    # Create cross-validation sets from the training data\n",
    "    cv_sets = ShuffleSplit(n_splits = 10, test_size = 0.20, random_state = 100)\n",
    "\n",
    "    # Create a decision tree regressor object\n",
    "    regressor = RandomForestRegressor()\n",
    "\n",
    "    # Create a dictionary for the parameter 'max_depth' with a range from 1 to 10\n",
    "    params = {'max_depth':[16, 17, 18]}\n",
    "\n",
    "    # Transform 'performance_metric' into a scoring function using 'make_scorer' \n",
    "    scoring_fnc = make_scorer(performance_metric)\n",
    "\n",
    "    # Create the grid search cv object --> GridSearchCV()\n",
    "    sc = createLocalSparkSession().sparkContext\n",
    "    grid = GridSearchCV(sc, estimator=regressor, param_grid=params, scoring=scoring_fnc, cv=cv_sets)\n",
    "\n",
    "    # Fit the grid search object to the data to compute the optimal model\n",
    "    tree_reg = grid.fit(X, y)\n",
    "    \n",
    "    # Return the best parameters after fitting the data\n",
    "    return tree_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter 'max_depth' is 17 for the optimal model.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# Fit the training data to the model using spark parallelized grid search CV\n",
    "forest_reg = RF_SparkizedGridSearchCV(df_train, df_price_train)\n",
    "\n",
    "# Takign best parameters\n",
    "bp = best_params(forest_reg)\n",
    "\n",
    "# Produce the optimal value for 'max_depth'\n",
    "print(\"Parameter 'max_depth' is {} for the optimal model.\".format(bp['max_depth']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 663 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=17,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the forest\n",
    "\n",
    "forest_reg_model = RandomForestRegressor(\n",
    "                              max_depth=bp['max_depth']\n",
    "                                 \n",
    ")\n",
    "\n",
    "%time forest_reg_model.fit(df_train, df_price_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 17}\n",
      "\n",
      "Random Forest Regressor score without CV on train set: 0.967\n",
      "Random Forest Regressor score without CV on test set: 0.872\n",
      "Random Forest Regressor Best score with CV=4: 0.880\n"
     ]
    }
   ],
   "source": [
    "# RandomForestRegressor score for price prediction\n",
    "\n",
    "print(bp)\n",
    "print(\"\\nRandom Forest Regressor score without CV on train set: %.3f\" % forest_reg_model.score(df_train, df_price_train)) #score on train set\n",
    "print(\"Random Forest Regressor score without CV on test set: %.3f\" % forest_reg_model.score(df_test, df_price_test)) #score on test set\n",
    "print(\"Random Forest Regressor Best score with CV=4: %.3f\" % best_score(forest_reg, 4)) # -> best score on test set is high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4047.5184930402106"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction on whole training set\n",
    "price_predictions_train = forest_reg_model.predict(df_train) #using the whole training set for making prediction with the final model given by the best CV parameters\n",
    "\n",
    "# Reversing np.log operation\n",
    "price_predictions_train_normal = np.exp(price_predictions_train)\n",
    "df_price_train_normal = np.exp(df_price_train)\n",
    "\n",
    "# MSE between target values (i.e known) and predicted values\n",
    "lin_mse = mean_squared_error(df_price_train_normal, price_predictions_train_normal)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50106.24367528 27406.55753769 13884.91642975 54675.18533109\n",
      " 35696.83976081 24597.35452694 35642.10554864 26155.63078519\n",
      "  6112.48003899 25640.28611567]\n",
      "\n",
      "\n",
      "[49486.999999998035, 29997.99999999986, 14995.000000000002, 55229.99999999814, 34498.000000000866, 22495.000000000615, 40278.99999999843, 27898.000000000535, 5650.000000000024, 25887.99999999954]\n"
     ]
    }
   ],
   "source": [
    "print(price_predictions_train_normal[10:20])\n",
    "print('\\n')\n",
    "print(list(df_price_train_normal[10:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7042.024876508299"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "price_predictions_test = forest_reg_model.predict(df_test)\n",
    "\n",
    "# Reversing np.log operation\n",
    "price_predictions_test_normal = np.exp(price_predictions_test)\n",
    "df_price_test_normal = np.exp(df_price_test)\n",
    "\n",
    "final_mse = mean_squared_error(df_price_test_normal, price_predictions_test_normal)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "\n",
    "final_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7451.3317218  38572.68546999 18225.74900844 31666.5499726\n",
      " 18108.86354096 34336.29850096 20453.37758642 22429.39804302\n",
      "  5527.14948323 22500.8997803 ]\n",
      "\n",
      "\n",
      "[6899.999999999999, 28699.99999999964, 16669.000000000033, 29995.000000000175, 19395.99999999995, 28999.9999999997, 27891.00000000092, 20994.999999999916, 4073.9999999999986, 23994.000000000626]\n"
     ]
    }
   ],
   "source": [
    "print(price_predictions_test_normal[10:20]) #predictions on test set\n",
    "print('\\n')\n",
    "print(list(df_price_test_normal[10:20])) #known values in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8305173078026042"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# r2 score between hold out prices and predicted prices\n",
    "r2_score(df_price_test_normal, price_predictions_test_normal, multioutput='variance_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model for type prediction\n",
    "pickle.dump(forest_reg_model, open(\"forest_reg_model_final.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model for type prediction\n",
    "forest_reg_model = pickle.load(open(\"forest_reg_model_final.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [6812.21784983 6695.08213232 6415.75210658 6228.02862027 8872.18994685\n",
      " 6083.23296031 6763.26311745 6288.19826871 6684.84074418 5923.02119675]\n",
      "Mean: 6676.58269432636\n",
      "Standard deviation: 786.5752777395389\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Cross val score on training set, although we already used grid search CV\n",
    "train_scores = cross_val_score(forest_reg_model, df_train, np.exp(df_price_train),\n",
    "                         scoring=\"neg_mean_squared_error\", cv=KFold(10, shuffle=True))\n",
    "forest_rmse_scores = np.sqrt(-train_scores)\n",
    "\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.80750046 0.8320772  0.8123264 ]\n",
      "Mean: 0.817301353281489\n",
      "Standard deviation: 0.010632236785498175\n"
     ]
    }
   ],
   "source": [
    "train_scores = cross_val_score(forest_reg_model, df_train, np.exp(df_price_train),\n",
    "                          cv=3)\n",
    "\n",
    "display_scores(train_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions on this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = forest_reg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on the hold out test set\n",
    "final_predictions = final_model.predict(df_test)\n",
    "\n",
    "final_mse = mean_squared_error(np.exp(df_price_test), np.exp(final_predictions))\n",
    "\n",
    "final_rmse = np.sqrt(final_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 7042.024877 \n",
      "Score on held-out Test Set: 0.871974 \n",
      "R2 Score: 0.830517\n"
     ]
    }
   ],
   "source": [
    "print(\"Test RMSE: %f \" % final_rmse)\n",
    "print(\"Score on held-out Test Set: %f \" % final_model.score(df_test, df_price_test))\n",
    "print(\"R2 Score: %f\" % r2_score(np.exp(df_price_test), np.exp(final_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [6480.53353471 6658.91437299 6594.26211655 6162.87540254 5849.15829075\n",
      " 7100.12167884 6127.91702225 6413.90220655 5829.90310809 6044.71107526]\n",
      "Mean: 6326.229880851052\n",
      "Standard deviation: 378.4346576071268\n"
     ]
    }
   ],
   "source": [
    "# Cross validation on the entire dataset, since we are good with out final model\n",
    "\n",
    "features = df_cleaned.drop(['Price'], axis=1)\n",
    "prices = df_cleaned['Price'].copy()\n",
    "\n",
    "final_rmses= cross_val_score(final_model, features, np.exp(prices),\n",
    "                          scoring=\"neg_mean_squared_error\", cv=KFold(10, shuffle=True))\n",
    "\n",
    "final_rmse_scores = np.sqrt(-final_rmses)\n",
    "display_scores(final_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.86358949 0.88391264 0.86823539 0.88739441 0.85360268 0.86539923\n",
      " 0.861056   0.86345341 0.83891033 0.8893061 ]\n",
      "Mean: 0.8674859671606686\n",
      "Standard deviation: 0.014930897222456116\n"
     ]
    }
   ],
   "source": [
    "final_scores = cross_val_score(forest_reg_model, features, np.exp(prices),\n",
    "                          cv=KFold(10, shuffle=True))\n",
    "\n",
    "display_scores(final_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
