{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree regression-Used Car Price Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine,inspect, func\n",
    "from config import password\n",
    "\n",
    "import seaborn as sns\n",
    "import scipy.stats as ss\n",
    "from collections import Counter\n",
    "import math \n",
    "from scipy import stats\n",
    "import datetime\n",
    "import matplotlib\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from spark_sklearn import GridSearchCV\n",
    "from spark_sklearn.util import createLocalSparkSession\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.compat import lzip\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the sql database\n",
    "connection_string = \"postgres:\"+password+\"@localhost:5432/hondadb\"\n",
    "engine = create_engine(f'postgresql://{connection_string}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = pd.read_sql(\"SELECT * FROM cleanedcardb2\",\n",
    "                     con=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Car Type', 'Model']\n",
    "les = {}\n",
    "\n",
    "for f in features:\n",
    "  les[f] = preprocessing.LabelEncoder()\n",
    "  les[f] = les[f].fit(df_cleaned[f])\n",
    "  df_cleaned[f] = les[f].transform(df_cleaned[f])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test sets\n",
    "train_set, test_set = train_test_split(df_cleaned, test_size = 0.3, random_state = 100)\n",
    "\n",
    "# Separating target labels from the rest\n",
    "df_train = train_set.drop(\"Price\", axis=1) #train without target\n",
    "df_price_train = train_set[\"Price\"].copy() #target\n",
    "\n",
    "df_test  = test_set.drop(\"Price\", axis=1)\n",
    "df_price_test = test_set[\"Price\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Score Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns the best score achieved by the model over all the cv splits\n",
    "def best_score(forest, cv):\n",
    "  best_score = 0\n",
    "  for i in range(0, cv):\n",
    "    items = list(map(lambda x: abs(x), forest.cv_results_['split'+str(i)+'_test_score']))\n",
    "    arr = np.append(best_score, items)\n",
    "    best_score = max(arr)\n",
    "  \n",
    "  return best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Param Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This functions returns the best combination of parameters, which allows to\n",
    "# get the best score\n",
    "def best_params(forest):\n",
    "  return forest.cv_results_['params'][forest.cv_results_['rank_test_score'][0]-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Metric Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def performance_metric(y_true, y_predict):\n",
    "    \"\"\" Calculates and returns the performance score between \n",
    "        true (y_true) and predicted (y_predict) values based on the metric chosen. \"\"\"\n",
    "    \n",
    "    score = r2_score(y_true, y_predict)\n",
    "    \n",
    "    # Return the score\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 'make_scorer', 'DecisionTreeRegressor', and 'GridSearchCV'\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def DT_SparkizedGridSearchCV(X, y):\n",
    "    \"\"\" Performs grid search over the 'max_depth' parameter for a \n",
    "        decision tree regressor trained on the input data [X, y]. \"\"\"\n",
    "    \n",
    "    # Create cross-validation sets from the training data\n",
    "    cv_sets = ShuffleSplit(n_splits = 10, test_size = 0.20, random_state = 42)\n",
    "\n",
    "    # Create a decision tree regressor object\n",
    "    regressor = DecisionTreeRegressor()\n",
    "\n",
    "    # Create a dictionary for the parameter 'max_depth' with a range from 1 to 10\n",
    "    params = {'max_depth':[1, 5, 10, 15, 16, 17]}\n",
    "\n",
    "    # Transform 'performance_metric' into a scoring function using 'make_scorer' \n",
    "    scoring_fnc = make_scorer(performance_metric)\n",
    "\n",
    "    # Create the grid search cv object --> GridSearchCV()\n",
    "    sc = createLocalSparkSession().sparkContext\n",
    "    grid = GridSearchCV(sc, estimator=regressor, param_grid=params, scoring=scoring_fnc, cv=cv_sets)\n",
    "\n",
    "    # Fit the grid search object to the data to compute the optimal model\n",
    "    tree_reg = grid.fit(X, y)\n",
    "    \n",
    "    # Return grid search output after fittig the data\n",
    "    return tree_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter 'max_depth' is 17 for the optimal model.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# Fit the training data to the model using spark parallelized grid search CV\n",
    "tree_reg = DT_SparkizedGridSearchCV(df_train, df_price_train)\n",
    "\n",
    "# Takign best parameters\n",
    "bp = best_params(tree_reg)\n",
    "\n",
    "# Produce the optimal value for 'max_depth'\n",
    "print(\"Parameter 'max_depth' is {} for the optimal model.\".format(bp['max_depth']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=17, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Due to the limitation of the spark-sklearn library's implementation of\n",
    "GridSearchCV, best_estimator_ parameter it's not available, so we need to\n",
    "fit a DecisionTreeRegressor on the best parameters given to us by gridSearchCV\n",
    "\"\"\"\n",
    "tree_reg_model = DecisionTreeRegressor(\n",
    "                              max_depth=bp['max_depth'])\n",
    "%time tree_reg_model.fit(df_train, df_price_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree Regressor parameters:\n",
      "{'max_depth': 17}\n",
      "\n",
      "Decision Tree Regressor score without CV on train set: 1.000\n",
      "Decision Tree Regressor score without CV on test set: 0.987\n",
      "Decision Tree Regressor Best score with CV=10: 0.997\n"
     ]
    }
   ],
   "source": [
    "# DecisionTreeRegressor score for price prediction\n",
    "\n",
    "\n",
    "print(\"Best Decision Tree Regressor parameters:\")\n",
    "print(bp)\n",
    "print(\"\\nDecision Tree Regressor score without CV on train set: %.3f\" % tree_reg_model.score(df_train, df_price_train)) #score on train set\n",
    "print(\"Decision Tree Regressor score without CV on test set: %.3f\" % tree_reg_model.score(df_test, df_price_test)) # score on test set\n",
    "print(\"Decision Tree Regressor Best score with CV=10: %.3f\" % best_score(tree_reg, 10)) # -> best score on test set is high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "775.183874092009"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction on whole training set\n",
    "price_predictions_train = tree_reg_model.predict(df_train) #using the whole training set for making prediction with the final model given by the best CV parameters\n",
    "\n",
    "# Reversing np.log operation\n",
    "price_predictions_train_normal = np.exp(price_predictions_train)\n",
    "df_price_train_normal = np.exp(df_price_train)\n",
    "\n",
    "# MSE between target values (i.e known) and predicted values\n",
    "lin_mse = mean_squared_error(df_price_train_normal, price_predictions_train_normal)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse # is higher than RMSE of linear regression, in fact the best score is smaller (0.58 vs 0.89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 94900.          85740.          10500.          42984.\n",
      "  94900.          85740.         146995.00000001  10988.\n",
      " 110000.         100615.        ]\n",
      "\n",
      "\n",
      "[94899.99999999812, 85740.00000000272, 10499.999999999955, 42984.00000000184, 94899.99999999812, 85740.00000000272, 146995.00000000652, 10987.999999999942, 110000.0000000052, 100615.00000000323]\n"
     ]
    }
   ],
   "source": [
    "print(price_predictions_train_normal[10:20])\n",
    "print('\\n')\n",
    "print(list(df_price_train_normal[10:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6343.803117633469"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "price_predictions_test = tree_reg_model.predict(df_test)\n",
    "\n",
    "# reversing np.log operation\n",
    "price_predictions_test_normal = np.exp(price_predictions_test)\n",
    "df_price_test_normal = np.exp(df_price_test)\n",
    "\n",
    "final_mse = mean_squared_error(df_price_test_normal, price_predictions_test_normal)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "\n",
    "final_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 17868.  85740.  57563. 113775.  22990. 113775.  66703.  37999.  41158.\n",
      "  44921.]\n",
      "\n",
      "\n",
      "[17868.0, 85740.00000000272, 57563.000000001215, 113774.99999999517, 22989.999999999374, 100615.00000000323, 66702.99999999985, 37999.00000000067, 66702.99999999985, 51720.99999999993]\n"
     ]
    }
   ],
   "source": [
    "print(price_predictions_test_normal[10:20]) #predictions on test set\n",
    "print('\\n')\n",
    "print(list(df_price_test_normal[10:20])) #known values in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9808276615986609"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(df_price_test_normal, price_predictions_test_normal, multioutput='variance_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model for type prediction\n",
    "pickle.dump(tree_reg_model, open(\"tree_reg_model_final.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model for type prediction\n",
    "tree_reg_model = pickle.load(open(\"tree_reg_model_final.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [6906.91178287 4111.26596022 4122.70715032 3811.67471041 6114.97961345\n",
      " 6388.72238056 6805.86866113 5168.32382844 6776.84752875 7394.60516849]\n",
      "Mean: 5760.190678464208\n",
      "Standard deviation: 1272.0678746579958\n"
     ]
    }
   ],
   "source": [
    "# Cross val score on training set\n",
    "\n",
    "train_scores = cross_val_score(tree_reg_model, df_train, np.exp(df_price_train),\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-train_scores)\n",
    "\n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.98772368 0.99339203 0.99095878 0.9935897  0.97867936 0.97928559\n",
      " 0.97484178 0.98842696 0.97473057 0.96810458]\n",
      "Mean: 0.9829733036444305\n",
      "Standard deviation: 0.008511840812894461\n"
     ]
    }
   ],
   "source": [
    "train_scores = cross_val_score(tree_reg_model, df_train, np.exp(df_price_train),\n",
    "                          cv=10)\n",
    "\n",
    "display_scores(train_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
